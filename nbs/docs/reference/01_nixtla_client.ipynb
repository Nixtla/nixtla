{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDK Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc\n",
    "from nixtla import NixtlaClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "## NixtlaClient\n",
       "\n",
       ">      NixtlaClient (api_key:Optional[str]=None, base_url:Optional[str]=None,\n",
       ">                    timeout:int=60, max_retries:int=6, retry_interval:int=10,\n",
       ">                    max_wait_time:int=360)\n",
       "\n",
       "*Client to interact with the Nixtla API.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| api_key | Optional | None | The authorization api_key interacts with the Nixtla API.<br>If not provided, will use the NIXTLA_API_KEY environment variable. |\n",
       "| base_url | Optional | None | Custom base_url.<br>If not provided, will use the NIXTLA_BASE_URL environment variable. |\n",
       "| timeout | int | 60 | Request timeout in seconds. Set this to `None` to disable it. |\n",
       "| max_retries | int | 6 | The maximum number of attempts to make when calling the API before giving up.<br>It defines how many times the client will retry the API call if it fails.<br>Default value is 6, indicating the client will attempt the API call up to 6 times in total |\n",
       "| retry_interval | int | 10 | The interval in seconds between consecutive retry attempts.<br>This is the waiting period before the client tries to call the API again after a failed attempt.<br>Default value is 10 seconds, meaning the client waits for 10 seconds between retries. |\n",
       "| max_wait_time | int | 360 | The maximum total time in seconds that the client will spend on all retry attempts before giving up.<br>This sets an upper limit on the cumulative waiting time for all retry attempts.<br>If this time is exceeded, the client will stop retrying and raise an exception.<br>Default value is 360 seconds, meaning the client will cease retrying if the total time<br>spent on retries exceeds 360 seconds.<br>The client throws a ReadTimeout error after 60 seconds of inactivity. If you want to<br>catch these errors, use max_wait_time >> 60. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "## NixtlaClient\n",
       "\n",
       ">      NixtlaClient (api_key:Optional[str]=None, base_url:Optional[str]=None,\n",
       ">                    timeout:int=60, max_retries:int=6, retry_interval:int=10,\n",
       ">                    max_wait_time:int=360)\n",
       "\n",
       "*Client to interact with the Nixtla API.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| api_key | Optional | None | The authorization api_key interacts with the Nixtla API.<br>If not provided, will use the NIXTLA_API_KEY environment variable. |\n",
       "| base_url | Optional | None | Custom base_url.<br>If not provided, will use the NIXTLA_BASE_URL environment variable. |\n",
       "| timeout | int | 60 | Request timeout in seconds. Set this to `None` to disable it. |\n",
       "| max_retries | int | 6 | The maximum number of attempts to make when calling the API before giving up.<br>It defines how many times the client will retry the API call if it fails.<br>Default value is 6, indicating the client will attempt the API call up to 6 times in total |\n",
       "| retry_interval | int | 10 | The interval in seconds between consecutive retry attempts.<br>This is the waiting period before the client tries to call the API again after a failed attempt.<br>Default value is 10 seconds, meaning the client waits for 10 seconds between retries. |\n",
       "| max_wait_time | int | 360 | The maximum total time in seconds that the client will spend on all retry attempts before giving up.<br>This sets an upper limit on the cumulative waiting time for all retry attempts.<br>If this time is exceeded, the client will stop retrying and raise an exception.<br>Default value is 360 seconds, meaning the client will cease retrying if the total time<br>spent on retries exceeds 360 seconds.<br>The client throws a ReadTimeout error after 60 seconds of inactivity. If you want to<br>catch these errors, use max_wait_time >> 60. |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "show_doc(NixtlaClient.__init__, title_level=2, name='NixtlaClient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "## NixtlaClient.validate_api_key\n",
       "\n",
       ">      NixtlaClient.validate_api_key (log:bool=True)\n",
       "\n",
       "*Check API key status.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| log | bool | True | Show the endpoint's response. |\n",
       "| **Returns** | **bool** |  | **Whether API key is valid.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "## NixtlaClient.validate_api_key\n",
       "\n",
       ">      NixtlaClient.validate_api_key (log:bool=True)\n",
       "\n",
       "*Check API key status.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| log | bool | True | Show the endpoint's response. |\n",
       "| **Returns** | **bool** |  | **Whether API key is valid.** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "show_doc(NixtlaClient.validate_api_key, title_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "## NixtlaClient.forecast\n",
       "\n",
       ">      NixtlaClient.forecast (df:~AnyDFType, h:typing.Annotated[int,Gt(gt=0)],\n",
       ">                             freq:Union[str,int,pandas._libs.tslibs.offsets.Bas\n",
       ">                             eOffset,NoneType]=None, id_col:str='unique_id',\n",
       ">                             time_col:str='ds', target_col:str='y',\n",
       ">                             X_df:Optional[~AnyDFType]=None,\n",
       ">                             level:Optional[list[Union[int,float]]]=None,\n",
       ">                             quantiles:Optional[list[float]]=None,\n",
       ">                             finetune_steps:typing.Annotated[int,Ge(ge=0)]=0,\n",
       ">                             finetune_depth:Literal[1,2,3,4,5]=1, finetune_loss\n",
       ">                             :Literal['default','mae','mse','rmse','mape','smap\n",
       ">                             e']='default',\n",
       ">                             finetuned_model_id:Optional[str]=None,\n",
       ">                             clean_ex_first:bool=True,\n",
       ">                             hist_exog_list:Optional[list[str]]=None,\n",
       ">                             validate_api_key:bool=False,\n",
       ">                             add_history:bool=False, date_features:Union[bool,l\n",
       ">                             ist[Union[str,Callable]]]=False, date_features_to_\n",
       ">                             one_hot:Union[bool,list[str]]=False, model:Literal\n",
       ">                             ['azureai','timegpt-1','timegpt-1-long-\n",
       ">                             horizon']='timegpt-1', num_partitions:Optional[Ann\n",
       ">                             otated[int,Gt(gt=0)]]=None,\n",
       ">                             feature_contributions:bool=False)\n",
       "\n",
       "*Forecast your time series using TimeGPT.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| df | AnyDFType |  | The DataFrame on which the function will operate. Expected to contain at least the following columns:<br>- time_col:<br>    Column name in `df` that contains the time indices of the time series. This is typically a datetime<br>    column with regular intervals, e.g., hourly, daily, monthly data points.<br>- target_col:<br>    Column name in `df` that contains the target variable of the time series, i.e., the variable we<br>    wish to predict or analyze.<br>Additionally, you can pass multiple time series (stacked in the dataframe) considering an additional column:<br>- id_col:<br>    Column name in `df` that identifies unique time series. Each unique value in this column<br>    corresponds to a unique time series. |\n",
       "| h | Annotated |  | Forecast horizon. |\n",
       "| freq | Union | None | Frequency of the timestamps. If `None`, it will be inferred automatically.<br>See [pandas' available frequencies](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases). |\n",
       "| id_col | str | unique_id | Column that identifies each serie. |\n",
       "| time_col | str | ds | Column that identifies each timestep, its values can be timestamps or integers. |\n",
       "| target_col | str | y | Column that contains the target. |\n",
       "| X_df | Optional | None | DataFrame with [`unique_id`, `ds`] columns and `df`'s future exogenous. |\n",
       "| level | Optional | None | Confidence levels between 0 and 100 for prediction intervals. |\n",
       "| quantiles | Optional | None | Quantiles to forecast, list between (0, 1).<br>`level` and `quantiles` should not be used simultaneously.<br>The output dataframe will have the quantile columns<br>formatted as TimeGPT-q-(100 * q) for each q.<br>100 * q represents percentiles but we choose this notation<br>to avoid having dots in column names. |\n",
       "| finetune_steps | Annotated | 0 | Number of steps used to finetune learning TimeGPT in the<br>new data. |\n",
       "| finetune_depth | Literal | 1 | The depth of the finetuning. Uses a scale from 1 to 5, where 1 means little finetuning,<br>and 5 means that the entire model is finetuned. |\n",
       "| finetune_loss | Literal | default | Loss function to use for finetuning. Options are: `default`, `mae`, `mse`, `rmse`, `mape`, and `smape`. |\n",
       "| finetuned_model_id | Optional | None | ID of previously fine-tuned model to use. |\n",
       "| clean_ex_first | bool | True | Clean exogenous signal before making forecasts using TimeGPT. |\n",
       "| hist_exog_list | Optional | None | Column names of the historical exogenous features. |\n",
       "| validate_api_key | bool | False | If True, validates api_key before sending requests. |\n",
       "| add_history | bool | False | Return fitted values of the model. |\n",
       "| date_features | Union | False | Features computed from the dates.<br>Can be pandas date attributes or functions that will take the dates as input.<br>If True automatically adds most used date features for the<br>frequency of `df`. |\n",
       "| date_features_to_one_hot | Union | False | Apply one-hot encoding to these date features.<br>If `date_features=True`, then all date features are<br>one-hot encoded by default. |\n",
       "| model | Literal | timegpt-1 | Model to use as a string. Options are: `timegpt-1`, and `timegpt-1-long-horizon`.<br>We recommend using `timegpt-1-long-horizon` for forecasting<br>if you want to predict more than one seasonal<br>period given the frequency of your data. |\n",
       "| num_partitions | Optional | None | Number of partitions to use.<br>If None, the number of partitions will be equal<br>to the available parallel resources in distributed environments. |\n",
       "| feature_contributions | bool | False |  |\n",
       "| **Returns** | **AnyDFType** |  | **DataFrame with TimeGPT forecasts for point predictions and probabilistic<br>predictions (if level is not None).** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "## NixtlaClient.forecast\n",
       "\n",
       ">      NixtlaClient.forecast (df:~AnyDFType, h:typing.Annotated[int,Gt(gt=0)],\n",
       ">                             freq:Union[str,int,pandas._libs.tslibs.offsets.Bas\n",
       ">                             eOffset,NoneType]=None, id_col:str='unique_id',\n",
       ">                             time_col:str='ds', target_col:str='y',\n",
       ">                             X_df:Optional[~AnyDFType]=None,\n",
       ">                             level:Optional[list[Union[int,float]]]=None,\n",
       ">                             quantiles:Optional[list[float]]=None,\n",
       ">                             finetune_steps:typing.Annotated[int,Ge(ge=0)]=0,\n",
       ">                             finetune_depth:Literal[1,2,3,4,5]=1, finetune_loss\n",
       ">                             :Literal['default','mae','mse','rmse','mape','smap\n",
       ">                             e']='default',\n",
       ">                             finetuned_model_id:Optional[str]=None,\n",
       ">                             clean_ex_first:bool=True,\n",
       ">                             hist_exog_list:Optional[list[str]]=None,\n",
       ">                             validate_api_key:bool=False,\n",
       ">                             add_history:bool=False, date_features:Union[bool,l\n",
       ">                             ist[Union[str,Callable]]]=False, date_features_to_\n",
       ">                             one_hot:Union[bool,list[str]]=False, model:Literal\n",
       ">                             ['azureai','timegpt-1','timegpt-1-long-\n",
       ">                             horizon']='timegpt-1', num_partitions:Optional[Ann\n",
       ">                             otated[int,Gt(gt=0)]]=None,\n",
       ">                             feature_contributions:bool=False)\n",
       "\n",
       "*Forecast your time series using TimeGPT.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| df | AnyDFType |  | The DataFrame on which the function will operate. Expected to contain at least the following columns:<br>- time_col:<br>    Column name in `df` that contains the time indices of the time series. This is typically a datetime<br>    column with regular intervals, e.g., hourly, daily, monthly data points.<br>- target_col:<br>    Column name in `df` that contains the target variable of the time series, i.e., the variable we<br>    wish to predict or analyze.<br>Additionally, you can pass multiple time series (stacked in the dataframe) considering an additional column:<br>- id_col:<br>    Column name in `df` that identifies unique time series. Each unique value in this column<br>    corresponds to a unique time series. |\n",
       "| h | Annotated |  | Forecast horizon. |\n",
       "| freq | Union | None | Frequency of the timestamps. If `None`, it will be inferred automatically.<br>See [pandas' available frequencies](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases). |\n",
       "| id_col | str | unique_id | Column that identifies each serie. |\n",
       "| time_col | str | ds | Column that identifies each timestep, its values can be timestamps or integers. |\n",
       "| target_col | str | y | Column that contains the target. |\n",
       "| X_df | Optional | None | DataFrame with [`unique_id`, `ds`] columns and `df`'s future exogenous. |\n",
       "| level | Optional | None | Confidence levels between 0 and 100 for prediction intervals. |\n",
       "| quantiles | Optional | None | Quantiles to forecast, list between (0, 1).<br>`level` and `quantiles` should not be used simultaneously.<br>The output dataframe will have the quantile columns<br>formatted as TimeGPT-q-(100 * q) for each q.<br>100 * q represents percentiles but we choose this notation<br>to avoid having dots in column names. |\n",
       "| finetune_steps | Annotated | 0 | Number of steps used to finetune learning TimeGPT in the<br>new data. |\n",
       "| finetune_depth | Literal | 1 | The depth of the finetuning. Uses a scale from 1 to 5, where 1 means little finetuning,<br>and 5 means that the entire model is finetuned. |\n",
       "| finetune_loss | Literal | default | Loss function to use for finetuning. Options are: `default`, `mae`, `mse`, `rmse`, `mape`, and `smape`. |\n",
       "| finetuned_model_id | Optional | None | ID of previously fine-tuned model to use. |\n",
       "| clean_ex_first | bool | True | Clean exogenous signal before making forecasts using TimeGPT. |\n",
       "| hist_exog_list | Optional | None | Column names of the historical exogenous features. |\n",
       "| validate_api_key | bool | False | If True, validates api_key before sending requests. |\n",
       "| add_history | bool | False | Return fitted values of the model. |\n",
       "| date_features | Union | False | Features computed from the dates.<br>Can be pandas date attributes or functions that will take the dates as input.<br>If True automatically adds most used date features for the<br>frequency of `df`. |\n",
       "| date_features_to_one_hot | Union | False | Apply one-hot encoding to these date features.<br>If `date_features=True`, then all date features are<br>one-hot encoded by default. |\n",
       "| model | Literal | timegpt-1 | Model to use as a string. Options are: `timegpt-1`, and `timegpt-1-long-horizon`.<br>We recommend using `timegpt-1-long-horizon` for forecasting<br>if you want to predict more than one seasonal<br>period given the frequency of your data. |\n",
       "| num_partitions | Optional | None | Number of partitions to use.<br>If None, the number of partitions will be equal<br>to the available parallel resources in distributed environments. |\n",
       "| feature_contributions | bool | False |  |\n",
       "| **Returns** | **AnyDFType** |  | **DataFrame with TimeGPT forecasts for point predictions and probabilistic<br>predictions (if level is not None).** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "show_doc(NixtlaClient.forecast, title_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "## NixtlaClient.cross_validation\n",
       "\n",
       ">      NixtlaClient.cross_validation (df:~AnyDFType,\n",
       ">                                     h:typing.Annotated[int,Gt(gt=0)], freq:Uni\n",
       ">                                     on[str,int,pandas._libs.tslibs.offsets.Bas\n",
       ">                                     eOffset,NoneType]=None,\n",
       ">                                     id_col:str='unique_id', time_col:str='ds',\n",
       ">                                     target_col:str='y', level:Optional[list[Un\n",
       ">                                     ion[int,float]]]=None,\n",
       ">                                     quantiles:Optional[list[float]]=None,\n",
       ">                                     validate_api_key:bool=False, n_windows:typ\n",
       ">                                     ing.Annotated[int,Gt(gt=0)]=1, step_size:O\n",
       ">                                     ptional[Annotated[int,Gt(gt=0)]]=None, fin\n",
       ">                                     etune_steps:typing.Annotated[int,Ge(ge=0)]\n",
       ">                                     =0, finetune_depth:Literal[1,2,3,4,5]=1, f\n",
       ">                                     inetune_loss:Literal['default','mae','mse'\n",
       ">                                     ,'rmse','mape','smape']='default',\n",
       ">                                     finetuned_model_id:Optional[str]=None,\n",
       ">                                     refit:bool=True, clean_ex_first:bool=True,\n",
       ">                                     hist_exog_list:Optional[list[str]]=None,\n",
       ">                                     date_features:Union[bool,list[str]]=False,\n",
       ">                                     date_features_to_one_hot:Union[bool,list[s\n",
       ">                                     tr]]=False, model:Literal['azureai','timeg\n",
       ">                                     pt-1','timegpt-1-long-\n",
       ">                                     horizon']='timegpt-1', num_partitions:Opti\n",
       ">                                     onal[Annotated[int,Gt(gt=0)]]=None)\n",
       "\n",
       "*Perform cross validation in your time series using TimeGPT.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| df | AnyDFType |  | The DataFrame on which the function will operate. Expected to contain at least the following columns:<br>- time_col:<br>    Column name in `df` that contains the time indices of the time series. This is typically a datetime<br>    column with regular intervals, e.g., hourly, daily, monthly data points.<br>- target_col:<br>    Column name in `df` that contains the target variable of the time series, i.e., the variable we<br>    wish to predict or analyze.<br>Additionally, you can pass multiple time series (stacked in the dataframe) considering an additional column:<br>- id_col:<br>    Column name in `df` that identifies unique time series. Each unique value in this column<br>    corresponds to a unique time series. |\n",
       "| h | Annotated |  | Forecast horizon. |\n",
       "| freq | Union | None | Frequency of the timestamps. If `None`, it will be inferred automatically.<br>See [pandas' available frequencies](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases). |\n",
       "| id_col | str | unique_id | Column that identifies each serie. |\n",
       "| time_col | str | ds | Column that identifies each timestep, its values can be timestamps or integers. |\n",
       "| target_col | str | y | Column that contains the target. |\n",
       "| level | Optional | None | Confidence level between 0 and 100 for prediction intervals. |\n",
       "| quantiles | Optional | None | Quantiles to forecast, list between (0, 1).<br>`level` and `quantiles` should not be used simultaneously.<br>The output dataframe will have the quantile columns<br>formatted as TimeGPT-q-(100 * q) for each q.<br>100 * q represents percentiles but we choose this notation<br>to avoid having dots in column names. |\n",
       "| validate_api_key | bool | False | If True, validates api_key before sending requests. |\n",
       "| n_windows | Annotated | 1 | Number of windows to evaluate. |\n",
       "| step_size | Optional | None | Step size between each cross validation window. If None it will be equal to `h`. |\n",
       "| finetune_steps | Annotated | 0 | Number of steps used to finetune TimeGPT in the<br>new data. |\n",
       "| finetune_depth | Literal | 1 | The depth of the finetuning. Uses a scale from 1 to 5, where 1 means little finetuning,<br>and 5 means that the entire model is finetuned. |\n",
       "| finetune_loss | Literal | default | Loss function to use for finetuning. Options are: `default`, `mae`, `mse`, `rmse`, `mape`, and `smape`. |\n",
       "| finetuned_model_id | Optional | None | ID of previously fine-tuned model to use. |\n",
       "| refit | bool | True | Fine-tune the model in each window. If `False`, only fine-tunes on the first window.<br>Only used if `finetune_steps` > 0. |\n",
       "| clean_ex_first | bool | True | Clean exogenous signal before making forecasts using TimeGPT. |\n",
       "| hist_exog_list | Optional | None | Column names of the historical exogenous features. |\n",
       "| date_features | Union | False | Features computed from the dates.<br>Can be pandas date attributes or functions that will take the dates as input.<br>If True automatically adds most used date features for the<br>frequency of `df`. |\n",
       "| date_features_to_one_hot | Union | False | Apply one-hot encoding to these date features.<br>If `date_features=True`, then all date features are<br>one-hot encoded by default. |\n",
       "| model | Literal | timegpt-1 | Model to use as a string. Options are: `timegpt-1`, and `timegpt-1-long-horizon`.<br>We recommend using `timegpt-1-long-horizon` for forecasting<br>if you want to predict more than one seasonal<br>period given the frequency of your data. |\n",
       "| num_partitions | Optional | None | Number of partitions to use.<br>If None, the number of partitions will be equal<br>to the available parallel resources in distributed environments. |\n",
       "| **Returns** | **AnyDFType** |  | **DataFrame with cross validation forecasts.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "## NixtlaClient.cross_validation\n",
       "\n",
       ">      NixtlaClient.cross_validation (df:~AnyDFType,\n",
       ">                                     h:typing.Annotated[int,Gt(gt=0)], freq:Uni\n",
       ">                                     on[str,int,pandas._libs.tslibs.offsets.Bas\n",
       ">                                     eOffset,NoneType]=None,\n",
       ">                                     id_col:str='unique_id', time_col:str='ds',\n",
       ">                                     target_col:str='y', level:Optional[list[Un\n",
       ">                                     ion[int,float]]]=None,\n",
       ">                                     quantiles:Optional[list[float]]=None,\n",
       ">                                     validate_api_key:bool=False, n_windows:typ\n",
       ">                                     ing.Annotated[int,Gt(gt=0)]=1, step_size:O\n",
       ">                                     ptional[Annotated[int,Gt(gt=0)]]=None, fin\n",
       ">                                     etune_steps:typing.Annotated[int,Ge(ge=0)]\n",
       ">                                     =0, finetune_depth:Literal[1,2,3,4,5]=1, f\n",
       ">                                     inetune_loss:Literal['default','mae','mse'\n",
       ">                                     ,'rmse','mape','smape']='default',\n",
       ">                                     finetuned_model_id:Optional[str]=None,\n",
       ">                                     refit:bool=True, clean_ex_first:bool=True,\n",
       ">                                     hist_exog_list:Optional[list[str]]=None,\n",
       ">                                     date_features:Union[bool,list[str]]=False,\n",
       ">                                     date_features_to_one_hot:Union[bool,list[s\n",
       ">                                     tr]]=False, model:Literal['azureai','timeg\n",
       ">                                     pt-1','timegpt-1-long-\n",
       ">                                     horizon']='timegpt-1', num_partitions:Opti\n",
       ">                                     onal[Annotated[int,Gt(gt=0)]]=None)\n",
       "\n",
       "*Perform cross validation in your time series using TimeGPT.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| df | AnyDFType |  | The DataFrame on which the function will operate. Expected to contain at least the following columns:<br>- time_col:<br>    Column name in `df` that contains the time indices of the time series. This is typically a datetime<br>    column with regular intervals, e.g., hourly, daily, monthly data points.<br>- target_col:<br>    Column name in `df` that contains the target variable of the time series, i.e., the variable we<br>    wish to predict or analyze.<br>Additionally, you can pass multiple time series (stacked in the dataframe) considering an additional column:<br>- id_col:<br>    Column name in `df` that identifies unique time series. Each unique value in this column<br>    corresponds to a unique time series. |\n",
       "| h | Annotated |  | Forecast horizon. |\n",
       "| freq | Union | None | Frequency of the timestamps. If `None`, it will be inferred automatically.<br>See [pandas' available frequencies](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases). |\n",
       "| id_col | str | unique_id | Column that identifies each serie. |\n",
       "| time_col | str | ds | Column that identifies each timestep, its values can be timestamps or integers. |\n",
       "| target_col | str | y | Column that contains the target. |\n",
       "| level | Optional | None | Confidence level between 0 and 100 for prediction intervals. |\n",
       "| quantiles | Optional | None | Quantiles to forecast, list between (0, 1).<br>`level` and `quantiles` should not be used simultaneously.<br>The output dataframe will have the quantile columns<br>formatted as TimeGPT-q-(100 * q) for each q.<br>100 * q represents percentiles but we choose this notation<br>to avoid having dots in column names. |\n",
       "| validate_api_key | bool | False | If True, validates api_key before sending requests. |\n",
       "| n_windows | Annotated | 1 | Number of windows to evaluate. |\n",
       "| step_size | Optional | None | Step size between each cross validation window. If None it will be equal to `h`. |\n",
       "| finetune_steps | Annotated | 0 | Number of steps used to finetune TimeGPT in the<br>new data. |\n",
       "| finetune_depth | Literal | 1 | The depth of the finetuning. Uses a scale from 1 to 5, where 1 means little finetuning,<br>and 5 means that the entire model is finetuned. |\n",
       "| finetune_loss | Literal | default | Loss function to use for finetuning. Options are: `default`, `mae`, `mse`, `rmse`, `mape`, and `smape`. |\n",
       "| finetuned_model_id | Optional | None | ID of previously fine-tuned model to use. |\n",
       "| refit | bool | True | Fine-tune the model in each window. If `False`, only fine-tunes on the first window.<br>Only used if `finetune_steps` > 0. |\n",
       "| clean_ex_first | bool | True | Clean exogenous signal before making forecasts using TimeGPT. |\n",
       "| hist_exog_list | Optional | None | Column names of the historical exogenous features. |\n",
       "| date_features | Union | False | Features computed from the dates.<br>Can be pandas date attributes or functions that will take the dates as input.<br>If True automatically adds most used date features for the<br>frequency of `df`. |\n",
       "| date_features_to_one_hot | Union | False | Apply one-hot encoding to these date features.<br>If `date_features=True`, then all date features are<br>one-hot encoded by default. |\n",
       "| model | Literal | timegpt-1 | Model to use as a string. Options are: `timegpt-1`, and `timegpt-1-long-horizon`.<br>We recommend using `timegpt-1-long-horizon` for forecasting<br>if you want to predict more than one seasonal<br>period given the frequency of your data. |\n",
       "| num_partitions | Optional | None | Number of partitions to use.<br>If None, the number of partitions will be equal<br>to the available parallel resources in distributed environments. |\n",
       "| **Returns** | **AnyDFType** |  | **DataFrame with cross validation forecasts.** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "show_doc(NixtlaClient.cross_validation, title_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "## NixtlaClient.detect_anomalies\n",
       "\n",
       ">      NixtlaClient.detect_anomalies (df:~AnyDFType,\n",
       ">                                     freq:Union[str,int,pandas._libs.tslibs.off\n",
       ">                                     sets.BaseOffset,NoneType]=None,\n",
       ">                                     id_col:str='unique_id', time_col:str='ds',\n",
       ">                                     target_col:str='y',\n",
       ">                                     level:Union[int,float]=99,\n",
       ">                                     finetuned_model_id:Optional[str]=None,\n",
       ">                                     clean_ex_first:bool=True,\n",
       ">                                     validate_api_key:bool=False,\n",
       ">                                     date_features:Union[bool,list[str]]=False,\n",
       ">                                     date_features_to_one_hot:Union[bool,list[s\n",
       ">                                     tr]]=False, model:Literal['azureai','timeg\n",
       ">                                     pt-1','timegpt-1-long-\n",
       ">                                     horizon']='timegpt-1', num_partitions:Opti\n",
       ">                                     onal[Annotated[int,Gt(gt=0)]]=None)\n",
       "\n",
       "*Detect anomalies in your time series using TimeGPT.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| df | AnyDFType |  | The DataFrame on which the function will operate. Expected to contain at least the following columns:<br>- time_col:<br>    Column name in `df` that contains the time indices of the time series. This is typically a datetime<br>    column with regular intervals, e.g., hourly, daily, monthly data points.<br>- target_col:<br>    Column name in `df` that contains the target variable of the time series, i.e., the variable we<br>    wish to predict or analyze.<br>Additionally, you can pass multiple time series (stacked in the dataframe) considering an additional column:<br>- id_col:<br>    Column name in `df` that identifies unique time series. Each unique value in this column<br>    corresponds to a unique time series. |\n",
       "| freq | Union | None | Frequency of the timestamps. If `None`, it will be inferred automatically.<br>See [pandas' available frequencies](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases). |\n",
       "| id_col | str | unique_id | Column that identifies each serie. |\n",
       "| time_col | str | ds | Column that identifies each timestep, its values can be timestamps or integers. |\n",
       "| target_col | str | y | Column that contains the target. |\n",
       "| level | Union | 99 | Confidence level between 0 and 100 for detecting the anomalies. |\n",
       "| finetuned_model_id | Optional | None | ID of previously fine-tuned model to use. |\n",
       "| clean_ex_first | bool | True | Clean exogenous signal before making forecasts<br>using TimeGPT. |\n",
       "| validate_api_key | bool | False | If True, validates api_key before sending requests. |\n",
       "| date_features | Union | False | Features computed from the dates.<br>Can be pandas date attributes or functions that will take the dates as input.<br>If True automatically adds most used date features for the<br>frequency of `df`. |\n",
       "| date_features_to_one_hot | Union | False | Apply one-hot encoding to these date features.<br>If `date_features=True`, then all date features are<br>one-hot encoded by default. |\n",
       "| model | Literal | timegpt-1 | Model to use as a string. Options are: `timegpt-1`, and `timegpt-1-long-horizon`.<br>We recommend using `timegpt-1-long-horizon` for forecasting<br>if you want to predict more than one seasonal<br>period given the frequency of your data. |\n",
       "| num_partitions | Optional | None | Number of partitions to use.<br>If None, the number of partitions will be equal<br>to the available parallel resources in distributed environments. |\n",
       "| **Returns** | **AnyDFType** |  | **DataFrame with anomalies flagged by TimeGPT.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "## NixtlaClient.detect_anomalies\n",
       "\n",
       ">      NixtlaClient.detect_anomalies (df:~AnyDFType,\n",
       ">                                     freq:Union[str,int,pandas._libs.tslibs.off\n",
       ">                                     sets.BaseOffset,NoneType]=None,\n",
       ">                                     id_col:str='unique_id', time_col:str='ds',\n",
       ">                                     target_col:str='y',\n",
       ">                                     level:Union[int,float]=99,\n",
       ">                                     finetuned_model_id:Optional[str]=None,\n",
       ">                                     clean_ex_first:bool=True,\n",
       ">                                     validate_api_key:bool=False,\n",
       ">                                     date_features:Union[bool,list[str]]=False,\n",
       ">                                     date_features_to_one_hot:Union[bool,list[s\n",
       ">                                     tr]]=False, model:Literal['azureai','timeg\n",
       ">                                     pt-1','timegpt-1-long-\n",
       ">                                     horizon']='timegpt-1', num_partitions:Opti\n",
       ">                                     onal[Annotated[int,Gt(gt=0)]]=None)\n",
       "\n",
       "*Detect anomalies in your time series using TimeGPT.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| df | AnyDFType |  | The DataFrame on which the function will operate. Expected to contain at least the following columns:<br>- time_col:<br>    Column name in `df` that contains the time indices of the time series. This is typically a datetime<br>    column with regular intervals, e.g., hourly, daily, monthly data points.<br>- target_col:<br>    Column name in `df` that contains the target variable of the time series, i.e., the variable we<br>    wish to predict or analyze.<br>Additionally, you can pass multiple time series (stacked in the dataframe) considering an additional column:<br>- id_col:<br>    Column name in `df` that identifies unique time series. Each unique value in this column<br>    corresponds to a unique time series. |\n",
       "| freq | Union | None | Frequency of the timestamps. If `None`, it will be inferred automatically.<br>See [pandas' available frequencies](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases). |\n",
       "| id_col | str | unique_id | Column that identifies each serie. |\n",
       "| time_col | str | ds | Column that identifies each timestep, its values can be timestamps or integers. |\n",
       "| target_col | str | y | Column that contains the target. |\n",
       "| level | Union | 99 | Confidence level between 0 and 100 for detecting the anomalies. |\n",
       "| finetuned_model_id | Optional | None | ID of previously fine-tuned model to use. |\n",
       "| clean_ex_first | bool | True | Clean exogenous signal before making forecasts<br>using TimeGPT. |\n",
       "| validate_api_key | bool | False | If True, validates api_key before sending requests. |\n",
       "| date_features | Union | False | Features computed from the dates.<br>Can be pandas date attributes or functions that will take the dates as input.<br>If True automatically adds most used date features for the<br>frequency of `df`. |\n",
       "| date_features_to_one_hot | Union | False | Apply one-hot encoding to these date features.<br>If `date_features=True`, then all date features are<br>one-hot encoded by default. |\n",
       "| model | Literal | timegpt-1 | Model to use as a string. Options are: `timegpt-1`, and `timegpt-1-long-horizon`.<br>We recommend using `timegpt-1-long-horizon` for forecasting<br>if you want to predict more than one seasonal<br>period given the frequency of your data. |\n",
       "| num_partitions | Optional | None | Number of partitions to use.<br>If None, the number of partitions will be equal<br>to the available parallel resources in distributed environments. |\n",
       "| **Returns** | **AnyDFType** |  | **DataFrame with anomalies flagged by TimeGPT.** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "show_doc(NixtlaClient.detect_anomalies, title_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "## NixtlaClient.usage\n",
       "\n",
       ">      NixtlaClient.usage ()\n",
       "\n",
       "*Query consumed requests and limits*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "## NixtlaClient.usage\n",
       "\n",
       ">      NixtlaClient.usage ()\n",
       "\n",
       "*Query consumed requests and limits*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "show_doc(NixtlaClient.usage, title_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "## NixtlaClient.finetune\n",
       "\n",
       ">      NixtlaClient.finetune\n",
       ">                             (df:Union[pandas.core.frame.DataFrame,polars.dataf\n",
       ">                             rame.frame.DataFrame], freq:Union[str,int,pandas._\n",
       ">                             libs.tslibs.offsets.BaseOffset,NoneType]=None,\n",
       ">                             id_col:str='unique_id', time_col:str='ds',\n",
       ">                             target_col:str='y',\n",
       ">                             finetune_steps:typing.Annotated[int,Ge(ge=0)]=10,\n",
       ">                             finetune_depth:Literal[1,2,3,4,5]=1, finetune_loss\n",
       ">                             :Literal['default','mae','mse','rmse','mape','smap\n",
       ">                             e']='default', output_model_id:Optional[str]=None,\n",
       ">                             finetuned_model_id:Optional[str]=None, model:Liter\n",
       ">                             al['azureai','timegpt-1','timegpt-1-long-\n",
       ">                             horizon']='timegpt-1')\n",
       "\n",
       "*Fine-tune TimeGPT to your series.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| df | Union |  | The DataFrame on which the function will operate. Expected to contain at least the following columns:<br>- time_col:<br>    Column name in `df` that contains the time indices of the time series. This is typically a datetime<br>    column with regular intervals, e.g., hourly, daily, monthly data points.<br>- target_col:<br>    Column name in `df` that contains the target variable of the time series, i.e., the variable we<br>    wish to predict or analyze.<br>Additionally, you can pass multiple time series (stacked in the dataframe) considering an additional column:<br>- id_col:<br>    Column name in `df` that identifies unique time series. Each unique value in this column<br>    corresponds to a unique time series. |\n",
       "| freq | Union | None | Frequency of the timestamps. If `None`, it will be inferred automatically.<br>See [pandas' available frequencies](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases). |\n",
       "| id_col | str | unique_id | Column that identifies each serie. |\n",
       "| time_col | str | ds | Column that identifies each timestep, its values can be timestamps or integers. |\n",
       "| target_col | str | y | Column that contains the target. |\n",
       "| finetune_steps | Annotated | 10 | Number of steps used to finetune learning TimeGPT in the new data. |\n",
       "| finetune_depth | Literal | 1 | The depth of the finetuning. Uses a scale from 1 to 5, where 1 means little finetuning,<br>and 5 means that the entire model is finetuned. |\n",
       "| finetune_loss | Literal | default | Loss function to use for finetuning. Options are: `default`, `mae`, `mse`, `rmse`, `mape`, and `smape`. |\n",
       "| output_model_id | Optional | None | ID to assign to the fine-tuned model. If `None`, an UUID is used. |\n",
       "| finetuned_model_id | Optional | None | ID of previously fine-tuned model to use as base. |\n",
       "| model | Literal | timegpt-1 | Model to use as a string. Options are: `timegpt-1`, and `timegpt-1-long-horizon`.<br>We recommend using `timegpt-1-long-horizon` for forecasting<br>if you want to predict more than one seasonal<br>period given the frequency of your data. |\n",
       "| **Returns** | **str** |  | **ID of the fine-tuned model** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "## NixtlaClient.finetune\n",
       "\n",
       ">      NixtlaClient.finetune\n",
       ">                             (df:Union[pandas.core.frame.DataFrame,polars.dataf\n",
       ">                             rame.frame.DataFrame], freq:Union[str,int,pandas._\n",
       ">                             libs.tslibs.offsets.BaseOffset,NoneType]=None,\n",
       ">                             id_col:str='unique_id', time_col:str='ds',\n",
       ">                             target_col:str='y',\n",
       ">                             finetune_steps:typing.Annotated[int,Ge(ge=0)]=10,\n",
       ">                             finetune_depth:Literal[1,2,3,4,5]=1, finetune_loss\n",
       ">                             :Literal['default','mae','mse','rmse','mape','smap\n",
       ">                             e']='default', output_model_id:Optional[str]=None,\n",
       ">                             finetuned_model_id:Optional[str]=None, model:Liter\n",
       ">                             al['azureai','timegpt-1','timegpt-1-long-\n",
       ">                             horizon']='timegpt-1')\n",
       "\n",
       "*Fine-tune TimeGPT to your series.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| df | Union |  | The DataFrame on which the function will operate. Expected to contain at least the following columns:<br>- time_col:<br>    Column name in `df` that contains the time indices of the time series. This is typically a datetime<br>    column with regular intervals, e.g., hourly, daily, monthly data points.<br>- target_col:<br>    Column name in `df` that contains the target variable of the time series, i.e., the variable we<br>    wish to predict or analyze.<br>Additionally, you can pass multiple time series (stacked in the dataframe) considering an additional column:<br>- id_col:<br>    Column name in `df` that identifies unique time series. Each unique value in this column<br>    corresponds to a unique time series. |\n",
       "| freq | Union | None | Frequency of the timestamps. If `None`, it will be inferred automatically.<br>See [pandas' available frequencies](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases). |\n",
       "| id_col | str | unique_id | Column that identifies each serie. |\n",
       "| time_col | str | ds | Column that identifies each timestep, its values can be timestamps or integers. |\n",
       "| target_col | str | y | Column that contains the target. |\n",
       "| finetune_steps | Annotated | 10 | Number of steps used to finetune learning TimeGPT in the new data. |\n",
       "| finetune_depth | Literal | 1 | The depth of the finetuning. Uses a scale from 1 to 5, where 1 means little finetuning,<br>and 5 means that the entire model is finetuned. |\n",
       "| finetune_loss | Literal | default | Loss function to use for finetuning. Options are: `default`, `mae`, `mse`, `rmse`, `mape`, and `smape`. |\n",
       "| output_model_id | Optional | None | ID to assign to the fine-tuned model. If `None`, an UUID is used. |\n",
       "| finetuned_model_id | Optional | None | ID of previously fine-tuned model to use as base. |\n",
       "| model | Literal | timegpt-1 | Model to use as a string. Options are: `timegpt-1`, and `timegpt-1-long-horizon`.<br>We recommend using `timegpt-1-long-horizon` for forecasting<br>if you want to predict more than one seasonal<br>period given the frequency of your data. |\n",
       "| **Returns** | **str** |  | **ID of the fine-tuned model** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "show_doc(NixtlaClient.finetune, title_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "## NixtlaClient.finetuned_models\n",
       "\n",
       ">      NixtlaClient.finetuned_models (as_df:bool=False)\n",
       "\n",
       "*List fine-tuned models*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| as_df | bool | False | Return the fine-tuned models as a pandas dataframe |\n",
       "| **Returns** | **Union** |  | **List of available fine-tuned models.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "## NixtlaClient.finetuned_models\n",
       "\n",
       ">      NixtlaClient.finetuned_models (as_df:bool=False)\n",
       "\n",
       "*List fine-tuned models*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| as_df | bool | False | Return the fine-tuned models as a pandas dataframe |\n",
       "| **Returns** | **Union** |  | **List of available fine-tuned models.** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "show_doc(NixtlaClient.finetuned_models, title_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "## NixtlaClient.delete_finetuned_model\n",
       "\n",
       ">      NixtlaClient.delete_finetuned_model (finetuned_model_id:str)\n",
       "\n",
       "*Delete a previously fine-tuned model*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| finetuned_model_id | str | ID of the fine-tuned model to be deleted. |\n",
       "| **Returns** | **bool** | **Whether delete was successful.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "## NixtlaClient.delete_finetuned_model\n",
       "\n",
       ">      NixtlaClient.delete_finetuned_model (finetuned_model_id:str)\n",
       "\n",
       "*Delete a previously fine-tuned model*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| finetuned_model_id | str | ID of the fine-tuned model to be deleted. |\n",
       "| **Returns** | **bool** | **Whether delete was successful.** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "show_doc(NixtlaClient.delete_finetuned_model, title_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "## NixtlaClient.plot\n",
       "\n",
       ">      NixtlaClient.plot (df:Union[pandas.core.frame.DataFrame,polars.dataframe.\n",
       ">                         frame.DataFrame,NoneType]=None, forecasts_df:Union[pan\n",
       ">                         das.core.frame.DataFrame,polars.dataframe.frame.DataFr\n",
       ">                         ame,NoneType]=None, id_col:str='unique_id',\n",
       ">                         time_col:str='ds', target_col:str='y', unique_ids:Unio\n",
       ">                         n[list[str],NoneType,numpy.ndarray]=None,\n",
       ">                         plot_random:bool=True, max_ids:int=8,\n",
       ">                         models:Optional[list[str]]=None,\n",
       ">                         level:Optional[list[Union[int,float]]]=None,\n",
       ">                         max_insample_length:Optional[int]=None,\n",
       ">                         plot_anomalies:bool=False,\n",
       ">                         engine:Literal['matplotlib','plotly','plotly-\n",
       ">                         resampler']='matplotlib',\n",
       ">                         resampler_kwargs:Optional[dict]=None, ax:Union[Forward\n",
       ">                         Ref('plt.Axes'),numpy.ndarray,ForwardRef('plotly.graph\n",
       ">                         _objects.Figure'),NoneType]=None)\n",
       "\n",
       "*Plot forecasts and insample values.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| df | Union | None | The DataFrame on which the function will operate. Expected to contain at least the following columns:<br>- time_col:<br>    Column name in `df` that contains the time indices of the time series. This is typically a datetime<br>    column with regular intervals, e.g., hourly, daily, monthly data points.<br>- target_col:<br>    Column name in `df` that contains the target variable of the time series, i.e., the variable we<br>    wish to predict or analyze.<br>Additionally, you can pass multiple time series (stacked in the dataframe) considering an additional column:<br>- id_col:<br>    Column name in `df` that identifies unique time series. Each unique value in this column<br>    corresponds to a unique time series. |\n",
       "| forecasts_df | Union | None | DataFrame with columns [`unique_id`, `ds`] and models. |\n",
       "| id_col | str | unique_id | Column that identifies each serie. |\n",
       "| time_col | str | ds | Column that identifies each timestep, its values can be timestamps or integers. |\n",
       "| target_col | str | y | Column that contains the target. |\n",
       "| unique_ids | Union | None | Time Series to plot.<br>If None, time series are selected randomly. |\n",
       "| plot_random | bool | True | Select time series to plot randomly. |\n",
       "| max_ids | int | 8 | Maximum number of ids to plot. |\n",
       "| models | Optional | None | list of models to plot. |\n",
       "| level | Optional | None | list of prediction intervals to plot if paseed. |\n",
       "| max_insample_length | Optional | None | Max number of train/insample observations to be plotted. |\n",
       "| plot_anomalies | bool | False | Plot anomalies for each prediction interval. |\n",
       "| engine | Literal | matplotlib | Library used to plot. 'matplotlib', 'plotly' or 'plotly-resampler'. |\n",
       "| resampler_kwargs | Optional | None | Kwargs to be passed to plotly-resampler constructor.<br>For further custumization (\"show_dash\") call the method,<br>store the plotting object and add the extra arguments to<br>its `show_dash` method. |\n",
       "| ax | Union | None | Object where plots will be added. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "## NixtlaClient.plot\n",
       "\n",
       ">      NixtlaClient.plot (df:Union[pandas.core.frame.DataFrame,polars.dataframe.\n",
       ">                         frame.DataFrame,NoneType]=None, forecasts_df:Union[pan\n",
       ">                         das.core.frame.DataFrame,polars.dataframe.frame.DataFr\n",
       ">                         ame,NoneType]=None, id_col:str='unique_id',\n",
       ">                         time_col:str='ds', target_col:str='y', unique_ids:Unio\n",
       ">                         n[list[str],NoneType,numpy.ndarray]=None,\n",
       ">                         plot_random:bool=True, max_ids:int=8,\n",
       ">                         models:Optional[list[str]]=None,\n",
       ">                         level:Optional[list[Union[int,float]]]=None,\n",
       ">                         max_insample_length:Optional[int]=None,\n",
       ">                         plot_anomalies:bool=False,\n",
       ">                         engine:Literal['matplotlib','plotly','plotly-\n",
       ">                         resampler']='matplotlib',\n",
       ">                         resampler_kwargs:Optional[dict]=None, ax:Union[Forward\n",
       ">                         Ref('plt.Axes'),numpy.ndarray,ForwardRef('plotly.graph\n",
       ">                         _objects.Figure'),NoneType]=None)\n",
       "\n",
       "*Plot forecasts and insample values.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| df | Union | None | The DataFrame on which the function will operate. Expected to contain at least the following columns:<br>- time_col:<br>    Column name in `df` that contains the time indices of the time series. This is typically a datetime<br>    column with regular intervals, e.g., hourly, daily, monthly data points.<br>- target_col:<br>    Column name in `df` that contains the target variable of the time series, i.e., the variable we<br>    wish to predict or analyze.<br>Additionally, you can pass multiple time series (stacked in the dataframe) considering an additional column:<br>- id_col:<br>    Column name in `df` that identifies unique time series. Each unique value in this column<br>    corresponds to a unique time series. |\n",
       "| forecasts_df | Union | None | DataFrame with columns [`unique_id`, `ds`] and models. |\n",
       "| id_col | str | unique_id | Column that identifies each serie. |\n",
       "| time_col | str | ds | Column that identifies each timestep, its values can be timestamps or integers. |\n",
       "| target_col | str | y | Column that contains the target. |\n",
       "| unique_ids | Union | None | Time Series to plot.<br>If None, time series are selected randomly. |\n",
       "| plot_random | bool | True | Select time series to plot randomly. |\n",
       "| max_ids | int | 8 | Maximum number of ids to plot. |\n",
       "| models | Optional | None | list of models to plot. |\n",
       "| level | Optional | None | list of prediction intervals to plot if paseed. |\n",
       "| max_insample_length | Optional | None | Max number of train/insample observations to be plotted. |\n",
       "| plot_anomalies | bool | False | Plot anomalies for each prediction interval. |\n",
       "| engine | Literal | matplotlib | Library used to plot. 'matplotlib', 'plotly' or 'plotly-resampler'. |\n",
       "| resampler_kwargs | Optional | None | Kwargs to be passed to plotly-resampler constructor.<br>For further custumization (\"show_dash\") call the method,<br>store the plotting object and add the extra arguments to<br>its `show_dash` method. |\n",
       "| ax | Union | None | Object where plots will be added. |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "show_doc(NixtlaClient.plot, title_level=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
