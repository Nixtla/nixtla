{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def colab_badge(path: str):\n",
    "    from IPython.display import Markdown\n",
    "    base_url = \"https://colab.research.google.com/github\"\n",
    "    badge_svg = \"https://colab.research.google.com/assets/colab-badge.svg\"\n",
    "    nb_url = f'{base_url}/Nixtla/nixtla/blob/main/nbs/{path}.ipynb'\n",
    "    badge_md = f\"[![]({badge_svg})]({nb_url})\"\n",
    "    display(Markdown(badge_md))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def in_colab():\n",
    "    return 'google.colab' in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _restrict_input_samples(level, input_size, model_horizon, h) -> int:\n",
    "    if level is not None:\n",
    "        # add sufficient info to compute\n",
    "        # conformal interval\n",
    "        # @AzulGarza\n",
    "        #  this is an old opinionated decision\n",
    "        #  about reducing the data sent to the api\n",
    "        #  to reduce latency when\n",
    "        #  a user passes level. since currently the model\n",
    "        #  uses conformal prediction, we can change a minimum\n",
    "        #  amount of data if the series are too large\n",
    "        new_input_size = 3 * input_size + max(model_horizon, h)\n",
    "    else:\n",
    "        # we only want to forecast\n",
    "        new_input_size = input_size\n",
    "    return new_input_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
