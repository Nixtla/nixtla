{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp distributed.nixtla_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import os\n",
    "\n",
    "import fugue\n",
    "import fugue.api as fa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fastcore.test import test_eq\n",
    "from dotenv import load_dotenv\n",
    "from utilsforecast.data import generate_series\n",
    "\n",
    "from nixtla import NixtlaClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def test_forecast(\n",
    "    df: fugue.AnyDataFrame, \n",
    "    horizon: int = 12,\n",
    "    id_col: str = 'unique_id',\n",
    "    time_col: str = 'ds',\n",
    "    **fcst_kwargs,\n",
    "):\n",
    "    fcst_df = nixtla_client.forecast(\n",
    "        df=df, \n",
    "        h=horizon,\n",
    "        id_col=id_col,\n",
    "        time_col=time_col,\n",
    "        **fcst_kwargs,\n",
    "    )\n",
    "    fcst_df = fa.as_pandas(fcst_df)\n",
    "    test_eq(n_series * 12, len(fcst_df))\n",
    "    cols = fcst_df.columns.to_list()\n",
    "    exp_cols = [id_col, time_col, 'TimeGPT']\n",
    "    if 'level' in fcst_kwargs:\n",
    "        level = sorted(fcst_kwargs['level'])\n",
    "        exp_cols.extend([f'TimeGPT-lo-{lv}' for lv in reversed(level)])\n",
    "        exp_cols.extend([f'TimeGPT-hi-{lv}' for lv in level])\n",
    "    test_eq(cols, exp_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import test_fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def test_forecast_diff_results_diff_models(\n",
    "    df: fugue.AnyDataFrame, \n",
    "    horizon: int = 12, \n",
    "    id_col: str = 'unique_id',\n",
    "    time_col: str = 'ds',\n",
    "    **fcst_kwargs,\n",
    "):\n",
    "    fcst_df = nixtla_client.forecast(\n",
    "        df=df, \n",
    "        h=horizon, \n",
    "        num_partitions=1,\n",
    "        id_col=id_col,\n",
    "        time_col=time_col,\n",
    "        model='timegpt-1',\n",
    "        **fcst_kwargs\n",
    "    )\n",
    "    fcst_df = fa.as_pandas(fcst_df)\n",
    "    fcst_df_2 = nixtla_client.forecast(\n",
    "        df=df, \n",
    "        h=horizon, \n",
    "        num_partitions=1,\n",
    "        id_col=id_col,\n",
    "        time_col=time_col,\n",
    "        model='timegpt-1-long-horizon',\n",
    "        **fcst_kwargs\n",
    "    )\n",
    "    fcst_df_2 = fa.as_pandas(fcst_df_2)\n",
    "    test_fail(\n",
    "        lambda: pd.testing.assert_frame_equal(\n",
    "            fcst_df.sort_values([id_col, time_col]).reset_index(drop=True),\n",
    "            fcst_df_2.sort_values([id_col, time_col]).reset_index(drop=True),\n",
    "        ),\n",
    "        contains='(column name=\"TimeGPT\") are different',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def test_forecast_same_results_num_partitions(\n",
    "    df: fugue.AnyDataFrame, \n",
    "    horizon: int = 12, \n",
    "    id_col: str = 'unique_id',\n",
    "    time_col: str = 'ds',\n",
    "    **fcst_kwargs,\n",
    "):\n",
    "    fcst_df = nixtla_client.forecast(\n",
    "        df=df, \n",
    "        h=horizon, \n",
    "        num_partitions=1,\n",
    "        id_col=id_col,\n",
    "        time_col=time_col,\n",
    "        **fcst_kwargs\n",
    "    )\n",
    "    fcst_df = fa.as_pandas(fcst_df)\n",
    "    fcst_df_2 = nixtla_client.forecast(\n",
    "        df=df, \n",
    "        h=horizon, \n",
    "        num_partitions=2,\n",
    "        id_col=id_col,\n",
    "        time_col=time_col,\n",
    "        **fcst_kwargs\n",
    "    )\n",
    "    fcst_df_2 = fa.as_pandas(fcst_df_2)\n",
    "    pd.testing.assert_frame_equal(\n",
    "        fcst_df.sort_values([id_col, time_col]).reset_index(drop=True),\n",
    "        fcst_df_2.sort_values([id_col, time_col]).reset_index(drop=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def test_cv_same_results_num_partitions(\n",
    "    df: fugue.AnyDataFrame, \n",
    "    horizon: int = 12, \n",
    "    id_col: str = 'unique_id',\n",
    "    time_col: str = 'ds',\n",
    "    **fcst_kwargs,\n",
    "):\n",
    "    fcst_df = nixtla_client.cross_validation(\n",
    "        df=df, \n",
    "        h=horizon, \n",
    "        num_partitions=1,\n",
    "        id_col=id_col,\n",
    "        time_col=time_col,\n",
    "        **fcst_kwargs\n",
    "    )\n",
    "    fcst_df = fa.as_pandas(fcst_df)\n",
    "    fcst_df_2 = nixtla_client.cross_validation(\n",
    "        df=df, \n",
    "        h=horizon, \n",
    "        num_partitions=2,\n",
    "        id_col=id_col,\n",
    "        time_col=time_col,\n",
    "        **fcst_kwargs\n",
    "    )\n",
    "    fcst_df_2 = fa.as_pandas(fcst_df_2)\n",
    "    pd.testing.assert_frame_equal(\n",
    "        fcst_df.sort_values([id_col, time_col]).reset_index(drop=True),\n",
    "        fcst_df_2.sort_values([id_col, time_col]).reset_index(drop=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def test_forecast_dataframe(df: fugue.AnyDataFrame):\n",
    "    test_cv_same_results_num_partitions(df, n_windows=2, step_size=1)\n",
    "    test_cv_same_results_num_partitions(df, n_windows=3, step_size=None, horizon=1)\n",
    "    test_cv_same_results_num_partitions(df, model='timegpt-1-long-horizon', horizon=1)\n",
    "    test_forecast_diff_results_diff_models(df)\n",
    "    test_forecast(df, num_partitions=1)\n",
    "    test_forecast(df, level=[90, 80], num_partitions=1)\n",
    "    test_forecast_same_results_num_partitions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def test_forecast_dataframe_diff_cols(\n",
    "    df: fugue.AnyDataFrame,\n",
    "    id_col: str = 'id_col',\n",
    "    time_col: str = 'time_col',\n",
    "    target_col: str = 'target_col',\n",
    "):\n",
    "    test_forecast(df, id_col=id_col, time_col=time_col, target_col=target_col, num_partitions=1)\n",
    "    test_forecast(\n",
    "        df, id_col=id_col, time_col=time_col, target_col=target_col, level=[90, 80], num_partitions=1\n",
    "    )\n",
    "    test_forecast_same_results_num_partitions(\n",
    "        df, id_col=id_col, time_col=time_col, target_col=target_col\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def test_forecast_x(\n",
    "    df: fugue.AnyDataFrame, \n",
    "    X_df: fugue.AnyDataFrame,\n",
    "    horizon: int = 24,\n",
    "    id_col: str = 'unique_id',\n",
    "    time_col: str = 'ds',\n",
    "    target_col: str = 'y',\n",
    "    **fcst_kwargs,\n",
    "):\n",
    "    fcst_df = nixtla_client.forecast(\n",
    "        df=df, \n",
    "        X_df=X_df,\n",
    "        h=horizon,\n",
    "        id_col=id_col,\n",
    "        time_col=time_col,\n",
    "        target_col=target_col,\n",
    "        **fcst_kwargs,\n",
    "    )\n",
    "    fcst_df = fa.as_pandas(fcst_df)\n",
    "    n_series = fa.as_pandas(X_df)[id_col].nunique()\n",
    "    test_eq(n_series * horizon, len(fcst_df))\n",
    "    cols = fcst_df.columns.to_list()\n",
    "    exp_cols = [id_col, time_col, 'TimeGPT']\n",
    "    if 'level' in fcst_kwargs:\n",
    "        level = sorted(fcst_kwargs['level'])\n",
    "        exp_cols.extend([f'TimeGPT-lo-{lv}' for lv in reversed(level)])\n",
    "        exp_cols.extend([f'TimeGPT-hi-{lv}' for lv in level])\n",
    "    test_eq(cols, exp_cols)\n",
    "    fcst_df_2 = nixtla_client.forecast(\n",
    "        df=fa.select(df, id_col, time_col, target_col), \n",
    "        h=horizon,\n",
    "        id_col=id_col,\n",
    "        time_col=time_col,\n",
    "        target_col=target_col,\n",
    "        **fcst_kwargs,\n",
    "    )\n",
    "    fcst_df_2 = fa.as_pandas(fcst_df_2)\n",
    "    equal_arrays = np.array_equal(\n",
    "        fcst_df.sort_values([id_col, time_col])['TimeGPT'].values,\n",
    "        fcst_df_2.sort_values([id_col, time_col])['TimeGPT'].values\n",
    "    )\n",
    "    assert not equal_arrays, 'Forecasts with and without ex vars are equal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def test_forecast_x_same_results_num_partitions(\n",
    "    df: fugue.AnyDataFrame, \n",
    "    X_df: fugue.AnyDataFrame,\n",
    "    horizon: int = 24, \n",
    "    id_col: str = 'unique_id',\n",
    "    time_col: str = 'ds',\n",
    "    target_col: str = 'y',\n",
    "    **fcst_kwargs,\n",
    "):\n",
    "    fcst_df = nixtla_client.forecast(\n",
    "        df=df, \n",
    "        X_df=X_df,\n",
    "        h=horizon, \n",
    "        num_partitions=1,\n",
    "        id_col=id_col,\n",
    "        time_col=time_col,\n",
    "        target_col=target_col,\n",
    "        **fcst_kwargs\n",
    "    )\n",
    "    fcst_df = fa.as_pandas(fcst_df)\n",
    "    fcst_df_2 = nixtla_client.forecast(\n",
    "        df=fa.select(df, id_col, time_col, target_col), \n",
    "        h=horizon,\n",
    "        num_partitions=2,\n",
    "        id_col=id_col,\n",
    "        time_col=time_col,\n",
    "        target_col=target_col,\n",
    "        **fcst_kwargs\n",
    "    )\n",
    "    fcst_df_2 = fa.as_pandas(fcst_df_2)\n",
    "    equal_arrays = np.array_equal(\n",
    "        fcst_df.sort_values([id_col, time_col])['TimeGPT'].values,\n",
    "        fcst_df_2.sort_values([id_col, time_col])['TimeGPT'].values\n",
    "    )\n",
    "    assert not equal_arrays, 'Forecasts with and without ex vars are equal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def test_forecast_x_dataframe(df: fugue.AnyDataFrame, X_df: fugue.AnyDataFrame):\n",
    "    test_forecast_x(df, X_df, num_partitions=1)\n",
    "    test_forecast_x(df, X_df, level=[90, 80], num_partitions=1)\n",
    "    test_forecast_x_same_results_num_partitions(df, X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def test_forecast_x_dataframe_diff_cols(\n",
    "    df: fugue.AnyDataFrame,\n",
    "    X_df: fugue.AnyDataFrame,\n",
    "    id_col: str = 'id_col',\n",
    "    time_col: str = 'time_col',\n",
    "    target_col: str = 'target_col'\n",
    "):\n",
    "    test_forecast_x(\n",
    "        df, X_df, id_col=id_col, time_col=time_col, target_col=target_col, num_partitions=1\n",
    "    )\n",
    "    test_forecast_x(\n",
    "        df, X_df, id_col=id_col, time_col=time_col, target_col=target_col, level=[90, 80], num_partitions=1\n",
    "    )\n",
    "    test_forecast_x_same_results_num_partitions(\n",
    "        df, X_df, id_col=id_col, time_col=time_col, target_col=target_col\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def test_anomalies(\n",
    "    df: fugue.AnyDataFrame, \n",
    "    id_col: str = 'unique_id',\n",
    "    time_col: str = 'ds',\n",
    "    target_col: str = 'y',\n",
    "    **anomalies_kwargs,\n",
    "):\n",
    "    anomalies_df = nixtla_client.detect_anomalies(\n",
    "        df=df, \n",
    "        id_col=id_col,\n",
    "        time_col=time_col,\n",
    "        target_col=target_col,\n",
    "        **anomalies_kwargs,\n",
    "    )\n",
    "    anomalies_df = fa.as_pandas(anomalies_df)\n",
    "    test_eq(fa.as_pandas(df)[id_col].unique(), anomalies_df[id_col].unique())\n",
    "    cols = anomalies_df.columns.to_list()\n",
    "    level = anomalies_kwargs.get('level', 99)\n",
    "    exp_cols = [\n",
    "        id_col,\n",
    "        time_col,\n",
    "        target_col,\n",
    "        'TimeGPT',\n",
    "        'anomaly',\n",
    "        f'TimeGPT-lo-{level}',\n",
    "        f'TimeGPT-hi-{level}',\n",
    "    ]\n",
    "    test_eq(cols, exp_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def test_anomalies_same_results_num_partitions(\n",
    "    df: fugue.AnyDataFrame, \n",
    "    id_col: str = 'unique_id',\n",
    "    time_col: str = 'ds',\n",
    "    target_col: str = 'y',\n",
    "    **anomalies_kwargs,\n",
    "):\n",
    "    anomalies_df = nixtla_client.detect_anomalies(\n",
    "        df=df, \n",
    "        num_partitions=1,\n",
    "        id_col=id_col,\n",
    "        time_col=time_col,\n",
    "        target_col=target_col,\n",
    "        **anomalies_kwargs\n",
    "    )\n",
    "    anomalies_df = fa.as_pandas(anomalies_df)\n",
    "    anomalies_df_2 = nixtla_client.detect_anomalies(\n",
    "        df=df, \n",
    "        num_partitions=2,\n",
    "        id_col=id_col,\n",
    "        time_col=time_col,\n",
    "        target_col=target_col,\n",
    "        **anomalies_kwargs\n",
    "    )\n",
    "    anomalies_df_2 = fa.as_pandas(anomalies_df_2)\n",
    "    pd.testing.assert_frame_equal(\n",
    "        anomalies_df.sort_values([id_col, time_col]).reset_index(drop=True),\n",
    "        anomalies_df_2.sort_values([id_col, time_col]).reset_index(drop=True),\n",
    "        atol=1e-5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def test_anomalies_diff_results_diff_models(\n",
    "    df: fugue.AnyDataFrame, \n",
    "    id_col: str = 'unique_id',\n",
    "    time_col: str = 'ds',\n",
    "    target_col: str = 'y',\n",
    "    **anomalies_kwargs,\n",
    "):\n",
    "    anomalies_df = nixtla_client.detect_anomalies(\n",
    "        df=df, \n",
    "        num_partitions=1,\n",
    "        id_col=id_col,\n",
    "        time_col=time_col,\n",
    "        target_col=target_col,\n",
    "        model='timegpt-1',\n",
    "        **anomalies_kwargs\n",
    "    )\n",
    "    anomalies_df = fa.as_pandas(anomalies_df)\n",
    "    anomalies_df_2 = nixtla_client.detect_anomalies(\n",
    "        df=df, \n",
    "        num_partitions=1,\n",
    "        id_col=id_col,\n",
    "        time_col=time_col,\n",
    "        target_col=target_col,\n",
    "        model='timegpt-1-long-horizon',\n",
    "        **anomalies_kwargs\n",
    "    )\n",
    "    anomalies_df_2 = fa.as_pandas(anomalies_df_2)\n",
    "    test_fail(\n",
    "        lambda: pd.testing.assert_frame_equal(\n",
    "            anomalies_df.sort_values([id_col, time_col]).reset_index(drop=True),\n",
    "            anomalies_df_2.sort_values([id_col, time_col]).reset_index(drop=True),\n",
    "        ),\n",
    "        contains='(column name=\"TimeGPT\") are different',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def test_anomalies_dataframe(df: fugue.AnyDataFrame):\n",
    "    test_anomalies(df, num_partitions=1)\n",
    "    test_anomalies(df, level=90, num_partitions=1)\n",
    "    test_anomalies_same_results_num_partitions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def test_anomalies_dataframe_diff_cols(\n",
    "    df: fugue.AnyDataFrame,\n",
    "    id_col: str = 'id_col',\n",
    "    time_col: str = 'time_col',\n",
    "    target_col: str = 'target_col',\n",
    "):\n",
    "    test_anomalies(df, id_col=id_col, time_col=time_col, target_col=target_col, num_partitions=1)\n",
    "    test_anomalies(df, id_col=id_col, time_col=time_col, target_col=target_col, level=90, num_partitions=1)\n",
    "    test_anomalies_same_results_num_partitions(df, id_col=id_col, time_col=time_col, target_col=target_col)\n",
    "    # @A: document behavior with exogenous variables in distributed environments.  \n",
    "    #test_anomalies_same_results_num_partitions(df, id_col=id_col, time_col=time_col, date_features=True, clean_ex_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def test_quantiles(df: fugue.AnyDataFrame, id_col: str = 'id_col', time_col: str = 'time_col'):\n",
    "    test_qls = list(np.arange(0.1, 1, 0.1))\n",
    "    exp_q_cols = [f\"TimeGPT-q-{int(q * 100)}\" for q in test_qls]\n",
    "    def test_method_qls(method, **kwargs):\n",
    "        df_qls = method(\n",
    "            df=df, \n",
    "            h=12, \n",
    "            id_col=id_col,\n",
    "            time_col=time_col, \n",
    "            quantiles=test_qls,\n",
    "            **kwargs\n",
    "        )\n",
    "        df_qls = fa.as_pandas(df_qls)\n",
    "        assert all(col in df_qls.columns for col in exp_q_cols)\n",
    "        # test monotonicity of quantiles\n",
    "        df_qls.apply(lambda x: x.is_monotonic_increasing, axis=1).sum() == len(exp_q_cols)\n",
    "    test_method_qls(nixtla_client.forecast)\n",
    "    test_method_qls(nixtla_client.forecast, add_history=True)\n",
    "    test_method_qls(nixtla_client.cross_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "nixtla_client = NixtlaClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "n_series = 4\n",
    "horizon = 7\n",
    "\n",
    "series = generate_series(n_series, min_length=100)\n",
    "series['unique_id'] = series['unique_id'].astype(str)\n",
    "\n",
    "series_diff_cols = series.copy()\n",
    "renamer = {'unique_id': 'id_col', 'ds': 'time_col', 'y': 'target_col'}\n",
    "series_diff_cols = series_diff_cols.rename(columns=renamer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# data for exogenous tests\n",
    "df_x = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short-with-ex-vars.csv',\n",
    "    parse_dates=['ds'],\n",
    ")\n",
    "df_x = df_x.rename(columns=str.lower)\n",
    "future_ex_vars_df = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short-future-ex-vars.csv',\n",
    "    parse_dates=['ds'],\n",
    ")\n",
    "future_ex_vars_df = future_ex_vars_df.rename(columns=str.lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark_df = spark.createDataFrame(series).repartition(2)\n",
    "spark_diff_cols_df = spark.createDataFrame(series_diff_cols).repartition(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nixtla_client = NixtlaClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_quantiles(spark_df, id_col=\"unique_id\", time_col=\"ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_forecast_dataframe(spark_df)\n",
    "test_forecast_dataframe_diff_cols(spark_diff_cols_df)\n",
    "test_anomalies_dataframe(spark_df)\n",
    "test_anomalies_dataframe_diff_cols(spark_diff_cols_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test exogenous variables\n",
    "spark_df_x = spark.createDataFrame(df_x).repartition(2)\n",
    "spark_future_ex_vars_df = spark.createDataFrame(future_ex_vars_df).repartition(2)\n",
    "test_forecast_x_dataframe(spark_df_x, spark_future_ex_vars_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test x different cols\n",
    "spark_df_x_diff_cols = spark.createDataFrame(df_x.rename(columns=renamer)).repartition(2)\n",
    "spark_future_ex_vars_df_diff_cols = spark.createDataFrame(\n",
    "    future_ex_vars_df.rename(columns=renamer)\n",
    ").repartition(2)\n",
    "test_forecast_x_dataframe_diff_cols(spark_df_x_diff_cols, spark_future_ex_vars_df_diff_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "dask_df = dd.from_pandas(series, npartitions=2)\n",
    "dask_diff_cols_df = dd.from_pandas(series_diff_cols, npartitions=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_quantiles(dask_df, id_col=\"unique_id\", time_col=\"ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_forecast_dataframe(dask_df)\n",
    "test_forecast_dataframe_diff_cols(dask_diff_cols_df)\n",
    "test_anomalies_dataframe(dask_df)\n",
    "test_anomalies_dataframe_diff_cols(dask_diff_cols_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test exogenous variables\n",
    "dask_df_x = dd.from_pandas(df_x, npartitions=2)\n",
    "dask_future_ex_vars_df = dd.from_pandas(future_ex_vars_df, npartitions=2)\n",
    "test_forecast_x_dataframe(dask_df_x, dask_future_ex_vars_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test x different cols\n",
    "dask_df_x_diff_cols = dd.from_pandas(df_x.rename(columns=renamer), npartitions=2)\n",
    "dask_future_ex_vars_df_diff_cols = dd.from_pandas(future_ex_vars_df.rename(columns=renamer), npartitions=2)\n",
    "test_forecast_x_dataframe_diff_cols(dask_df_x_diff_cols, dask_future_ex_vars_df_diff_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import ray\n",
    "from ray.cluster_utils import Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "ray_cluster = Cluster(\n",
    "    initialize_head=True,\n",
    "    head_node_args={\"num_cpus\": 2}\n",
    ")\n",
    "ray.init(address=ray_cluster.address, ignore_reinit_error=True)\n",
    "# add mock node to simulate a cluster\n",
    "mock_node = ray_cluster.add_node(num_cpus=2)\n",
    "ray_df = ray.data.from_pandas(series)\n",
    "ray_diff_cols_df = ray.data.from_pandas(series_diff_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_quantiles(ray_df, id_col=\"unique_id\", time_col=\"ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_forecast_dataframe(ray_df)\n",
    "test_forecast_dataframe_diff_cols(ray_diff_cols_df)\n",
    "test_anomalies_dataframe(ray_df)\n",
    "test_anomalies_dataframe_diff_cols(ray_diff_cols_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test exogenous variables\n",
    "ray_df_x = ray.data.from_pandas(df_x)\n",
    "ray_future_ex_vars_df = ray.data.from_pandas(future_ex_vars_df)\n",
    "test_forecast_x_dataframe(ray_df_x, ray_future_ex_vars_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test x different cols\n",
    "ray_df_x_diff_cols = ray.data.from_pandas(df_x.rename(columns=renamer))\n",
    "ray_future_ex_vars_df_diff_cols = ray.data.from_pandas(future_ex_vars_df.rename(columns=renamer))\n",
    "test_forecast_x_dataframe_diff_cols(ray_df_x_diff_cols, ray_future_ex_vars_df_diff_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
