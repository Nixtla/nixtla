{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ff81b5a-514d-4d8b-953e-c8f7cb4ba215",
   "metadata": {},
   "source": [
    "# How to on Spark: Forecasting\n",
    "> Run TimeGPT distributedly on top of Spark.\n",
    "\n",
    "`TimeGPT` works on top of Spark, Dask, and Ray through Fugue. `TimeGPT` will read the input DataFrame and use the corresponding engine. For example, if the input is a Spark DataFrame, `TimeGPT` will use the existing Spark session to run the forecast.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3119cd0-9b9d-4df9-9779-005847c46048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nixtlats.utils import colab_badge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd11fae-3219-4ffc-b2de-a96542362d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "colab_badge('docs/how-to-guides/0_distributed_fcst_spark')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "361d702c-361f-4321-85d3-2b76fb7b4937",
   "metadata": {},
   "source": [
    "# Installation "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2854f3c-7dc4-4615-9a85-7d7762fea647",
   "metadata": {},
   "source": [
    "As long as Spark is installed and configured, `TimeGPT` will be able to use it. If executing on a distributed Spark cluster, make use the `nixtlats` library is installed across all the workers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "743b89bd-6406-4f90-b545-2bd84a8ae62a",
   "metadata": {},
   "source": [
    "## Executing on Spark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b18574a5-76f8-4156-8264-9adae43e715d",
   "metadata": {},
   "source": [
    "To run the forecasts distributed on Spark, just pass in a Spark DataFrame instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434c950c-6252-4696-8ea8-2e1bb865847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5b9207c-29d1-4034-8d2e-223abc831cf1",
   "metadata": {},
   "source": [
    "Instantiate `NixtlaClient` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf6004b-ebd0-4a3c-8c02-d5463c62f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nixtlats import NixtlaClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec2b1fb-74fb-4464-b57b-84c676cb997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nixtla_client = NixtlaClient(\n",
    "    # defaults to os.environ.get(\"NIXTLA_API_KEY\")\n",
    "    api_key = 'my_api_key_provided_by_nixtla'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57091ace-6068-410d-82fc-2b0bd20d63c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "nixtla_client = NixtlaClient()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "357aade9-ffaa-44c6-b9cb-48be7bda71f4",
   "metadata": {},
   "source": [
    "Use Spark as an engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7644af0-f628-46ea-8fb7-474ee2fca39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "395152be-c5c7-46bb-85d8-da739d470834",
   "metadata": {},
   "source": [
    "### Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ac9c73-6644-47be-884c-23a682844e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df = 'https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short.csv'\n",
    "spark_df = spark.createDataFrame(pd.read_csv(url_df))\n",
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305167a0-1984-4004-aea3-b97402832491",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst_df = nixtla_client.forecast(spark_df, h=12)\n",
    "fcst_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdb15c0-1e13-43fc-a3ea-8f75b87cd71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import test_fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce55c5fa-ddd7-454a-aa43-697aa8c805d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test different results for different models\n",
    "fcst_df_1 = fcst_df.toPandas()\n",
    "fcst_df_2 = nixtla_client.forecast(spark_df, h=12, model='timegpt-1-long-horizon')\n",
    "fcst_df_2 = fcst_df_2.toPandas()\n",
    "test_fail(\n",
    "    lambda: pd.testing.assert_frame_equal(fcst_df_1[['TimeGPT']], fcst_df_2[['TimeGPT']]),\n",
    "    contains='(column name=\"TimeGPT\") are different'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2008fbf0-9bd2-4974-904b-bb8dc90876e6",
   "metadata": {},
   "source": [
    "### Forecast with exogenous variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d281c8d-3a5c-4b3e-8468-7699ef44933b",
   "metadata": {},
   "source": [
    "Exogenous variables or external factors are crucial in time series forecasting as they provide additional information that might influence the prediction. These variables could include holiday markers, marketing spending, weather data, or any other external data that correlate with the time series data you are forecasting.\n",
    "\n",
    "For example, if you're forecasting ice cream sales, temperature data could serve as a useful exogenous variable. On hotter days, ice cream sales may increase.\n",
    "\n",
    "To incorporate exogenous variables in TimeGPT, you'll need to pair each point in your time series data with the corresponding external data.\n",
    "\n",
    "Let's see an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d7fd4-5d69-4b6e-b065-efeba63f5911",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short-with-ex-vars.csv')\n",
    "spark_df = spark.createDataFrame(df)\n",
    "spark_df.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5172dc4a-66dd-47dd-a30d-228bc2f14317",
   "metadata": {},
   "source": [
    "To produce forecasts we have to add the future values of the exogenous variables. Let's read this dataset. In this case we want to predict 24 steps ahead, therefore each unique id will have 24 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8697301-e53b-446b-a965-6f57383d1d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_ex_vars_df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short-future-ex-vars.csv')\n",
    "spark_future_ex_vars_df = spark.createDataFrame(future_ex_vars_df)\n",
    "spark_future_ex_vars_df.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66ec94e4-98c5-48ee-ad2f-d6996e82b758",
   "metadata": {},
   "source": [
    "Let's call the `forecast` method, adding this information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c51169-3561-4d00-adba-fd6e49ab6c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "timegpt_fcst_ex_vars_df = nixtla_client.forecast(df=spark_df, X_df=spark_future_ex_vars_df, h=24, level=[80, 90])\n",
    "timegpt_fcst_ex_vars_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620ef1e3-da4f-4949-bf12-6fd3727dfec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
