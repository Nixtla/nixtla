---
title: "Controlling the Anomaly Detection Process"
description: "Learn how to refine TimeGPT's anomaly detection process by tuning parameters for improved accuracy and alignment with specific use cases."
icon: "brain"
---


## Why Anomaly Detection?
TimeGPT leverages forecast errors to identify anomalies in your time-series data. By optimizing parameters, you can detect subtle deviations and customize results for specific use cases.

## Key Parameters

• **detection_size** determines data window size for threshold calculation.<br/>
• **level** sets confidence intervals for anomaly thresholds.<br/>
• **freq** aligns detection with data frequency (e.g., "D" for daily).

## How to Adjust the Anomaly Detection Process

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Nixtla/nixtla/blob/main/nbs/docs/capabilities/online-anomaly-detection/02_adjusting_detection_process.ipynb)

### Step 1: Install and Import Dependencies

In your environment, install and import the necessary libraries:

```python
import pandas as pd
from nixtla import NixtlaClient
import matplotlib.pyplot as plt
```

### Step 2: Initialize the Nixtla Client

Create an instance of NixtlaClient with your API key:

```python
nixtla_client = NixtlaClient(api_key='my_api_key_provided_by_nixtla')
```


### Step 3: Conduct a baseline detection

Load a portion of the Peyton Manning dataset to illustrate the default anomaly detection process:

```python
df = pd.read_csv(
    'https://datasets-nixtla.s3.amazonaws.com/peyton-manning.csv',
    parse_dates=['ds']
).tail(200)

df.head()
```

| x      | unique_id   | ds           | y          |
| ------ | ----------- | ------------ | ---------- |
| 2764   | 0           | 2015-07-05   | 6.499787   |
| 2765   | 0           | 2015-07-06   | 6.859615   |
| 2766   | 0           | 2015-07-07   | 6.881411   |
| 2767   | 0           | 2015-07-08   | 6.997596   |
| 2768   | 0           | 2015-07-09   | 7.152269   |


Set a baseline by using only the default parameters of the method.


```python
anomaly_df = nixtla_client.detect_anomalies_online(
    df,
    freq='D',
    h=14,
    level=80,
    detection_size=150
)
```


```bash Baseline Detection Log Output
INFO:nixtla.nixtla_client:Validating inputs...
INFO:nixtla.nixtla_client:Preprocessing dataframes...
WARNING:nixtla.nixtla_client:Detection size is large. Using the entire series to compute the anomaly threshold...
INFO:nixtla.nixtla_client:Calling Online Anomaly Detector Endpoint...
```


<Frame caption="Baseline Anomaly Detection Visualization">
  ![Baseline Anomaly Detection Visualization](https://raw.githubusercontent.com/Nixtla/nixtla/readme_docs/nbs/_docs/docs/capabilities/online-anomaly-detection/02_adjusting_detection_process_files/figure-markdown_strict/cell-13-output-1.png)
</Frame>

### Step 4: Fine-tuned detection

TimeGPT detects anomalies based on forecast errors. By improving your model's forecasts, you can strengthen anomaly detection performance. The following parameters can be fine-tuned:

- **finetune_steps**: Number of additional training iterations
- **finetune_depth**: Depth level for refining the model
- **finetune_loss**: Loss function used during fine-tuning

```python
anomaly_online_ft = nixtla_client.detect_anomalies_online(
    df,
    freq='D',
    h=14,
    level=80,
    detection_size=150,
    finetune_steps=10,
    finetune_depth=2,
    finetune_loss='mae'
)
```

```bash Fine-tuned Detection Log Output
INFO:nixtla.nixtla_client:Validating inputs...
INFO:nixtla.nixtla_client:Preprocessing dataframes...
WARNING:nixtla.nixtla_client:Detection size is large. Using the entire series to compute the anomaly threshold...
INFO:nixtla.nixtla_client:Calling Online Anomaly Detector Endpoint...
```

<Frame caption="Fine-tuned TimeGPT Anomaly Detection">
  ![Fine-tuned TimeGPT Anomaly Detection](https://raw.githubusercontent.com/Nixtla/nixtla/readme_docs/nbs/_docs/docs/capabilities/online-anomaly-detection/02_adjusting_detection_process_files/figure-markdown_strict/cell-15-output-1.png)
</Frame>

From the plot above, we can see that fewer anomalies were detected by the model, since the fine-tuning process helps TimeGPT better forecast the series.

### Step 5: Adjusting Forecast Horizon and Step Size

Similar to cross-validation, the anomaly detection method generates forecasts for historical data by splitting the time series into multiple windows. The way these windows are defined can impact the anomaly detection results. Two key parameters control this process:

* `h`: Specifies how many steps into the future the forecast is made for each window.
* `step_size`: Determines the interval between the starting points of consecutive windows.

Note that when `step_size` is smaller than `h`, then we get overlapping windows. This can make the detection process more robust, as TimeGPT will see the same time step more than once. However, this comes with a computational cost, since the same time step will be predicted more than once.
```python
anomaly_df_horizon = nixtla_client.detect_anomalies_online(
    df,
    time_col='ds',
    target_col='y',
    freq='D',
    h=2,
    step_size=1,
    level=80,
    detection_size=150
)
```

<Frame caption="Adjusted Horizon and Step Size Visualization">
  ![Adjusted Horizon and Step Size Visualization](https://raw.githubusercontent.com/Nixtla/nixtla/readme_docs/nbs/_docs/docs/capabilities/online-anomaly-detection/02_adjusting_detection_process_files/figure-markdown_strict/cell-17-output-1.png)
</Frame>

**Choosing `h` and `step_size`** depends on the nature of your data:
- Frequent or short anomalies: Use smaller `h` and `step_size`
- Smooth or longer trends: Choose larger `h` and `step_size`